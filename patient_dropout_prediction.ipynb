{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Patient Dropout Prediction Model\n",
        "\n",
        "This notebook builds an XGBoost classifier to predict patient dropout from clinical trials using Python libraries.\n",
        "\n",
        "**Features:**\n",
        "- **Age**: Patient age (0-99)\n",
        "- **Gender**: Patient gender (MALE/FEMALE)\n",
        "- **Target**: patient_dropout indicator (1 = dropout, 0 = completed)\n",
        "\n",
        "**Tech Stack:**\n",
        "- Snowpark for Python (data access)\n",
        "- XGBoost (gradient boosting classifier)\n",
        "- scikit-learn (preprocessing & metrics)\n",
        "- pandas (data manipulation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "### Import Required Libraries\n",
        "\n",
        "# Snowpark for Python\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import snowflake.snowpark.functions as F\n",
        "\n",
        "# Data science libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Scikit-learn for preprocessing and metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, \n",
        "    precision_score, \n",
        "    recall_score, \n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Misc\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Establish Snowflake session\n",
        "session = get_active_session()\n",
        "\n",
        "# Add query tag for tracking\n",
        "session.query_tag = {\n",
        "    \"origin\": \"patient_dropout_ml\",\n",
        "    \"model\": \"xgboost_classifier\",\n",
        "    \"version\": {\"major\": 1, \"minor\": 0}\n",
        "}\n",
        "\n",
        "print(\"Session established successfully!\")\n",
        "session\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Training Data\n",
        "\n",
        "Load the patient dropout data from INFORMATICS_SANDBOX.ML_TEST.DOR_ANALYSIS_FF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Load the training data from Snowflake table\n",
        "patient_data_df = session.table(\"INFORMATICS_SANDBOX.ML_TEST.DOR_ANALYSIS_FF\")\n",
        "\n",
        "# Display basic info\n",
        "print(f\"Total records: {patient_data_df.count()}\")\n",
        "patient_data_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Check the schema\n",
        "patient_data_df.describe()\n",
        "\n",
        "# Show column names and types\n",
        "for field in patient_data_df.schema.fields:\n",
        "    print(f\"{field.name}: {field.datatype}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Convert to pandas for analysis and visualization\n",
        "patient_pd = patient_data_df.to_pandas()\n",
        "\n",
        "# Display first few rows\n",
        "print(\"Sample data:\")\n",
        "patient_pd.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Check data distribution\n",
        "print(\"=== Dataset Overview ===\")\n",
        "print(f\"Total patients: {len(patient_pd)}\")\n",
        "print(f\"Dropout count: {patient_pd['PATIENT_DROPOUT'].sum()}\")\n",
        "print(f\"Dropout percentage: {patient_pd['PATIENT_DROPOUT'].mean() * 100:.2f}%\")\n",
        "print(f\"\\nAge statistics:\")\n",
        "print(f\"  Mean age: {patient_pd['AGE'].mean():.2f}\")\n",
        "print(f\"  Min age: {patient_pd['AGE'].min()}\")\n",
        "print(f\"  Max age: {patient_pd['AGE'].max()}\")\n",
        "print(f\"  Std age: {patient_pd['AGE'].std():.2f}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"\\nMissing values:\")\n",
        "print(patient_pd.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Dropout rate by gender\n",
        "print(\"=== Dropout Rate by Gender ===\")\n",
        "gender_stats = patient_pd.groupby('GENDER').agg({\n",
        "    'PATIENT_DROPOUT': ['count', 'sum', 'mean']\n",
        "}).round(4)\n",
        "gender_stats.columns = ['Total_Patients', 'Dropout_Count', 'Dropout_Rate']\n",
        "gender_stats['Dropout_Percentage'] = gender_stats['Dropout_Rate'] * 100\n",
        "print(gender_stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Dropout rate by age group\n",
        "print(\"\\n=== Dropout Rate by Age Group ===\")\n",
        "patient_pd['AGE_GROUP'] = pd.cut(\n",
        "    patient_pd['AGE'], \n",
        "    bins=[0, 30, 50, 70, 100],\n",
        "    labels=['18-29', '30-49', '50-69', '70+']\n",
        ")\n",
        "\n",
        "age_stats = patient_pd.groupby('AGE_GROUP').agg({\n",
        "    'PATIENT_DROPOUT': ['count', 'sum', 'mean']\n",
        "}).round(4)\n",
        "age_stats.columns = ['Total_Patients', 'Dropout_Count', 'Dropout_Rate']\n",
        "age_stats['Dropout_Percentage'] = age_stats['Dropout_Rate'] * 100\n",
        "print(age_stats)\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Dropout rate by age group\n",
        "age_stats['Dropout_Percentage'].plot(kind='bar', ax=axes[0], color='steelblue')\n",
        "axes[0].set_title('Dropout Rate by Age Group')\n",
        "axes[0].set_ylabel('Dropout Percentage (%)')\n",
        "axes[0].set_xlabel('Age Group')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Dropout rate by gender\n",
        "gender_stats['Dropout_Percentage'].plot(kind='bar', ax=axes[1], color='coral')\n",
        "axes[1].set_title('Dropout Rate by Gender')\n",
        "axes[1].set_ylabel('Dropout Percentage (%)')\n",
        "axes[1].set_xlabel('Gender')\n",
        "axes[1].tick_params(axis='x', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Preprocessing\n",
        "\n",
        "Prepare features for XGBoost model training by encoding categorical variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Define feature columns and target\n",
        "FEATURE_COLUMNS = ['AGE', 'GENDER']\n",
        "TARGET_COLUMN = 'PATIENT_DROPOUT'\n",
        "\n",
        "# Create a clean dataframe with only required columns\n",
        "df_clean = patient_pd[FEATURE_COLUMNS + [TARGET_COLUMN]].copy()\n",
        "\n",
        "# Handle case variations in gender\n",
        "df_clean['GENDER'] = df_clean['GENDER'].str.upper()\n",
        "\n",
        "# Encode gender: MALE = 1, FEMALE = 0\n",
        "df_clean['GENDER_ENCODED'] = (df_clean['GENDER'] == 'MALE').astype(int)\n",
        "\n",
        "# Drop the original gender column\n",
        "df_clean = df_clean.drop('GENDER', axis=1)\n",
        "\n",
        "# Remove AGE_GROUP if it exists (was created for EDA only)\n",
        "if 'AGE_GROUP' in df_clean.columns:\n",
        "    df_clean = df_clean.drop('AGE_GROUP', axis=1)\n",
        "\n",
        "print(\"Preprocessed data shape:\", df_clean.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df_clean.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Verify no missing values and data types\n",
        "print(\"Data Info:\")\n",
        "print(df_clean.info())\n",
        "print(\"\\nData Statistics:\")\n",
        "print(df_clean.describe())\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df_clean[TARGET_COLUMN].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train/Test Split\n",
        "\n",
        "Split the data into training and testing sets following best practices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Prepare features (X) and target (y)\n",
        "X = df_clean[['AGE', 'GENDER_ENCODED']]\n",
        "y = df_clean[TARGET_COLUMN]\n",
        "\n",
        "# Split into train and test sets (80/20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2, \n",
        "    random_state=42,\n",
        "    stratify=y  # Maintain class distribution in both sets\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Test set size: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "print(f\"\\nTraining set dropout rate: {y_train.mean()*100:.2f}%\")\n",
        "print(f\"Test set dropout rate: {y_test.mean()*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train XGBoost Model\n",
        "\n",
        "Train an XGBoost classifier following the pattern from MEDPACE_ML_HOL notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Initialize XGBoost Classifier\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,        # Number of trees\n",
        "    max_depth=6,             # Maximum tree depth\n",
        "    learning_rate=0.1,       # Step size shrinkage\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'    # Evaluation metric\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training XGBoost model...\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# Display feature importance\n",
        "feature_names = ['AGE', 'GENDER_ENCODED']\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': xgb_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Visualize feature importance\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='skyblue')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.title('XGBoost Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Make Predictions\n",
        "\n",
        "Generate predictions on both training and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Generate predictions on test set\n",
        "y_test_pred = xgb_model.predict(X_test)\n",
        "y_test_pred_proba = xgb_model.predict_proba(X_test)[:, 1]  # Probability of dropout\n",
        "\n",
        "# Generate predictions on training set (to check for overfitting)\n",
        "y_train_pred = xgb_model.predict(X_train)\n",
        "y_train_pred_proba = xgb_model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "print(\"Predictions generated successfully!\")\n",
        "print(f\"Test predictions shape: {y_test_pred.shape}\")\n",
        "print(f\"Training predictions shape: {y_train_pred.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Create a predictions dataframe for test set\n",
        "test_predictions_df = pd.DataFrame({\n",
        "    'AGE': X_test['AGE'].values,\n",
        "    'GENDER_ENCODED': X_test['GENDER_ENCODED'].values,\n",
        "    'Actual_Dropout': y_test.values,\n",
        "    'Predicted_Dropout': y_test_pred,\n",
        "    'Dropout_Probability': y_test_pred_proba\n",
        "})\n",
        "\n",
        "print(\"Sample predictions:\")\n",
        "print(test_predictions_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "## 8. Model Evaluation - Test Set Performance\n",
        "\n",
        "Calculate comprehensive evaluation metrics on the test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calculate test set metrics\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "test_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "print(\"=== TEST SET PERFORMANCE ===\")\n",
        "print(f\"Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall:    {test_recall:.4f}\")\n",
        "print(f\"F1 Score:  {test_f1:.4f}\")\n",
        "print(f\"ROC AUC:   {test_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Calculate training set metrics (to check for overfitting)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_precision = precision_score(y_train, y_train_pred)\n",
        "train_recall = recall_score(y_train, y_train_pred)\n",
        "train_f1 = f1_score(y_train, y_train_pred)\n",
        "train_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
        "\n",
        "print(\"\\n=== TRAINING SET PERFORMANCE ===\")\n",
        "print(f\"Accuracy:  {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
        "print(f\"Precision: {train_precision:.4f}\")\n",
        "print(f\"Recall:    {train_recall:.4f}\")\n",
        "print(f\"F1 Score:  {train_f1:.4f}\")\n",
        "print(f\"ROC AUC:   {train_auc:.4f}\")\n",
        "\n",
        "# Check for overfitting\n",
        "print(\"\\n=== OVERFITTING CHECK ===\")\n",
        "print(f\"Accuracy difference: {abs(train_accuracy - test_accuracy):.4f}\")\n",
        "if abs(train_accuracy - test_accuracy) < 0.05:\n",
        "    print(\"✓ Model generalizes well (difference < 5%)\")\n",
        "else:\n",
        "    print(\"⚠ Possible overfitting detected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n=== CONFUSION MATRIX ===\")\n",
        "print(f\"True Negatives:  {cm[0,0]}\")\n",
        "print(f\"False Positives: {cm[0,1]}\")\n",
        "print(f\"False Negatives: {cm[1,0]}\")\n",
        "print(f\"True Positives:  {cm[1,1]}\")\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['No Dropout', 'Dropout'],\n",
        "            yticklabels=['No Dropout', 'Dropout'])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix - Test Set')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print(\"\\n=== CLASSIFICATION REPORT ===\")\n",
        "print(classification_report(y_test, y_test_pred, \n",
        "                          target_names=['No Dropout', 'Dropout']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. ROC Curve and AUC\n",
        "\n",
        "Visualize model performance across different classification thresholds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {test_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "## 10. Predict on New Patients\n",
        "\n",
        "Apply the trained model to score new patients for dropout risk.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create sample new patients to score\n",
        "new_patients_data = pd.DataFrame({\n",
        "    'AGE': [25, 45, 65, 30, 75, 22, 55, 40, 80, 28],\n",
        "    'GENDER': ['FEMALE', 'MALE', 'FEMALE', 'MALE', 'FEMALE', \n",
        "               'MALE', 'FEMALE', 'MALE', 'MALE', 'FEMALE']\n",
        "})\n",
        "\n",
        "print(\"New patients to score:\")\n",
        "print(new_patients_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Preprocess new patients (same as training data)\n",
        "new_patients_data['GENDER_ENCODED'] = (new_patients_data['GENDER'].str.upper() == 'MALE').astype(int)\n",
        "\n",
        "# Prepare features for prediction\n",
        "X_new = new_patients_data[['AGE', 'GENDER_ENCODED']]\n",
        "\n",
        "print(\"\\nPreprocessed features:\")\n",
        "print(X_new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Make predictions on new patients\n",
        "new_predictions = xgb_model.predict(X_new)\n",
        "new_predictions_proba = xgb_model.predict_proba(X_new)[:, 1]\n",
        "\n",
        "# Create results dataframe\n",
        "new_patients_results = new_patients_data.copy()\n",
        "new_patients_results['Predicted_Dropout'] = new_predictions\n",
        "new_patients_results['Dropout_Probability'] = new_predictions_proba\n",
        "\n",
        "# Add risk category\n",
        "def categorize_risk(prob):\n",
        "    if prob >= 0.7:\n",
        "        return 'High Risk'\n",
        "    elif prob >= 0.4:\n",
        "        return 'Medium Risk'\n",
        "    else:\n",
        "        return 'Low Risk'\n",
        "\n",
        "new_patients_results['Risk_Category'] = new_patients_results['Dropout_Probability'].apply(categorize_risk)\n",
        "\n",
        "print(\"\\n=== NEW PATIENT PREDICTIONS ===\")\n",
        "print(new_patients_results[['AGE', 'GENDER', 'Dropout_Probability', 'Risk_Category']].sort_values('Dropout_Probability', ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Visualize risk distribution for new patients\n",
        "risk_counts = new_patients_results['Risk_Category'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Risk category distribution\n",
        "risk_counts.plot(kind='bar', ax=axes[0], color=['red', 'orange', 'green'])\n",
        "axes[0].set_title('Risk Category Distribution - New Patients')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_xlabel('Risk Category')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Dropout probability distribution\n",
        "axes[1].hist(new_patients_results['Dropout_Probability'], bins=10, color='steelblue', edgecolor='black')\n",
        "axes[1].set_title('Dropout Probability Distribution')\n",
        "axes[1].set_xlabel('Dropout Probability')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].axvline(0.4, color='orange', linestyle='--', label='Medium Risk Threshold')\n",
        "axes[1].axvline(0.7, color='red', linestyle='--', label='High Risk Threshold')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "## 11. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Summary\n",
        "\n",
        "**Data Source:**\n",
        "- Table: INFORMATICS_SANDBOX.ML_TEST.DOR_ANALYSIS_FF\n",
        "- Features: Age (numeric), Gender (categorical)\n",
        "- Target: Patient_Dropout (binary: 1=dropout, 0=completed)\n",
        "\n",
        "**Model Details:**\n",
        "- Algorithm: XGBoost Classifier\n",
        "- Implementation: Python (xgboost library)\n",
        "- Train/Test Split: 80/20 with stratification\n",
        "\n",
        "**Model Performance:**\n",
        "- Test Accuracy: {printed above}\n",
        "- Test AUC: {printed above}  \n",
        "- Precision, Recall, F1: {printed above}\n",
        "\n",
        "**Workflow:**\n",
        "1. ✅ Load data from Snowflake using Snowpark\n",
        "2. ✅ Exploratory data analysis with visualizations\n",
        "3. ✅ Feature encoding (Gender → binary)\n",
        "4. ✅ Train/test split with stratification\n",
        "5. ✅ XGBoost model training\n",
        "6. ✅ Comprehensive evaluation (accuracy, precision, recall, F1, AUC, confusion matrix, ROC curve)\n",
        "7. ✅ Production scoring on new patients with risk categorization\n",
        "\n",
        "### Potential Improvements\n",
        "\n",
        "1. **Feature Engineering:**\n",
        "   - Add medical history features\n",
        "   - Include trial duration and phase\n",
        "   - Add previous trial participation data\n",
        "   - Create age bins or polynomial features\n",
        "\n",
        "2. **Model Enhancements:**\n",
        "   - Hyperparameter tuning with GridSearchCV or RandomizedSearchCV\n",
        "   - Try ensemble methods (Random Forest, LightGBM)\n",
        "   - Implement SMOTE or class weighting if imbalanced\n",
        "   - Feature selection techniques\n",
        "\n",
        "3. **MLOps:**\n",
        "   - Integrate with Snowflake Model Registry\n",
        "   - Set up model monitoring and drift detection\n",
        "   - Create automated retraining pipeline\n",
        "   - Deploy as Snowflake UDF for real-time scoring\n",
        "\n",
        "4. **Validation:**\n",
        "   - Implement k-fold cross-validation\n",
        "   - Test on multiple clinical trial datasets\n",
        "   - Perform temporal validation (train on old data, test on recent)\n",
        "\n",
        "5. **Interpretability:**\n",
        "   - Add SHAP values for model explainability\n",
        "   - Create feature importance visualizations\n",
        "   - Analyze misclassified cases\n",
        "5. Address class imbalance if present (SMOTE, class weights)\n",
        "6. Create a production deployment pipeline\n",
        "7. Integrate with Snowflake Feature Store and Model Registry\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Model Persistence (Optional)\n",
        "\n",
        "Save the trained XGBoost model for future use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "# Optional: Save model to file for later use\n",
        "# Uncomment to save the model\n",
        "\n",
        "# import joblib\n",
        "# import os\n",
        "\n",
        "# # Create models directory if it doesn't exist\n",
        "# os.makedirs('/tmp/models', exist_ok=True)\n",
        "\n",
        "# # Save the model\n",
        "# model_path = '/tmp/models/patient_dropout_xgboost.joblib'\n",
        "# joblib.dump(xgb_model, model_path)\n",
        "# print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "# # To load the model later:\n",
        "# # loaded_model = joblib.load(model_path)\n",
        "# # predictions = loaded_model.predict(X_new)\n",
        "\n",
        "print(\"Model training and evaluation complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
